{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13e6298-b916-4eaf-847f-a49cdbdbb133",
   "metadata": {
    "id": "0e9c1462-91a7-4d3c-b02b-1161380ffcf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 2022\n",
      "/opt/conda/envs/venv/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v2.0.0. You can import it from `pytorch_lightning.utilities` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+    LOADING DATA    +-----------------------------+\n",
      "\n",
      "+================================================================================+\n",
      "                      Model name: flair-one-baseline_argu                       \n",
      "+================================================================================+\n",
      "[---TASKING---]\n",
      "- use weights              :    True\n",
      "- use metadata             :    False\n",
      "- use augmentation         :    True\n",
      "\n",
      "+--------------------------------------------------------------------------------+\n",
      "[---DATA SPLIT---]\n",
      "- train                    :    50697 samples\n",
      "- val                      :    11015 samples\n",
      "- test                     :    15700 samples\n",
      "\n",
      "+--------------------------------------------------------------------------------+\n",
      "[---HYPER-PARAMETERS---]\n",
      "- batch size               :    8\n",
      "- learning rate            :    0.02\n",
      "- epochs                   :    20\n",
      "- nodes                    :    1\n",
      "- GPU per nodes            :    1\n",
      "- accelerator              :    gpu\n",
      "- workers                  :    0\n",
      "\n",
      "+--------------------------------------------------------------------------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#general \n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path \n",
    "\n",
    "#deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress.tqdm_progress import TQDMProgressBar\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "try:\n",
    "  from pytorch_lightning.utilities.distributed import rank_zero_only\n",
    "except ImportError:\n",
    "  from pytorch_lightning.utilities.rank_zero import rank_zero_only  \n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "#flair-one baseline modules \n",
    "from py_module.utils import load_data, subset_debug\n",
    "from py_module.datamodule import OCS_DataModule\n",
    "from py_module.model import SMP_Unet_meta\n",
    "from py_module.task_module import SegmentationTask\n",
    "from py_module.writer import PredictionWriter\n",
    "\n",
    "##############################################################################################\n",
    "# paths and naming\n",
    "path_data = \"./toy_dataset_flair-one/\" # toy (or full) dataset folder\n",
    "path_metadata_file = \"./metadata/flair-one_TOY_metadata.json\" # json file containing the metadata\n",
    "\n",
    "out_folder = \"/content/gdrive/MyDrive/models_output/\" # output directory for logs and predictions.\n",
    "out_model_name = \"flair-one-baseline_argu\" # to keep track\n",
    "##############################################################################################\n",
    "\n",
    "##############################################################################################\n",
    "# tasking\n",
    "use_weights = True \n",
    "class_weights = [1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0]\n",
    "\n",
    "use_metadata = False\n",
    "use_augmentation = True\n",
    "##############################################################################################\n",
    "\n",
    "##############################################################################################\n",
    "# training hyper-parameters\n",
    "batch_size = 8\n",
    "learning_rate = 0.02\n",
    "num_epochs = 20\n",
    "##############################################################################################\n",
    "\n",
    "##############################################################################################\n",
    "# computational ressources\n",
    "accelerator = 'gpu' # set to 'cpu' if GPU not available\n",
    "gpus_per_node = 1 # set to 1 if mono-GPU\n",
    "num_nodes = 1 # set to 1 if mono-GPU\n",
    "strategy = None # Put this parameter to None if train on only one GPU or on CPUs. If multiple GPU, set to 'ddp'\n",
    "num_workers = 0\n",
    "##############################################################################################\n",
    "\n",
    "##############################################################################################\n",
    "# display\n",
    "enable_progress_bar = True\n",
    "progress_rate = 10 #tqdm update rate during training \n",
    "##############################################################################################\n",
    "\n",
    "out_dir = Path(out_folder, out_model_name)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "seed_everything(2022, workers=True)\n",
    "\n",
    "@rank_zero_only\n",
    "def step_loading(path_data, path_metadata_file: str, use_metadata: bool) -> dict:\n",
    "    print('+'+'-'*29+'+', '   LOADING DATA   ', '+'+'-'*29+'+')\n",
    "    train, val, test = load_data(path_data, path_metadata_file, use_metadata=use_metadata)\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "@rank_zero_only\n",
    "def print_recap():\n",
    "    print('\\n+'+'='*80+'+',f\"{'Model name: '+out_model_name : ^80}\", '+'+'='*80+'+', f\"{'[---TASKING---]'}\", sep='\\n')\n",
    "    for info, val in zip([\"use weights\", \"use metadata\", \"use augmentation\"], [use_weights, use_metadata, use_augmentation]): print(f\"- {info:25s}: {'':3s}{val}\")\n",
    "    print('\\n+'+'-'*80+'+', f\"{'[---DATA SPLIT---]'}\", sep='\\n')\n",
    "    for split_name, d in zip([\"train\", \"val\", \"test\"], [dict_train, dict_val, dict_test]): print(f\"- {split_name:25s}: {'':3s}{len(d['IMG'])} samples\")\n",
    "    print('\\n+'+'-'*80+'+', f\"{'[---HYPER-PARAMETERS---]'}\", sep='\\n')\n",
    "    for info, val in zip([\"batch size\", \"learning rate\", \"epochs\", \"nodes\", \"GPU per nodes\", \"accelerator\", \"workers\"], [batch_size, learning_rate, num_epochs, num_nodes, gpus_per_node, accelerator, num_workers]): print(f\"- {info:25s}: {'':3s}{val}\")        \n",
    "    print('\\n+'+'-'*80+'+', '\\n')\n",
    "\n",
    "dict_train, dict_val, dict_test = step_loading(path_data, path_metadata_file, use_metadata=use_metadata)  \n",
    "print_recap()\n",
    "\n",
    "\n",
    "\n",
    "if use_augmentation == True:\n",
    "    transform_set = A.Compose([ \n",
    "                                A.VerticalFlip(p=0.5),\n",
    "                                A.HorizontalFlip(p=0.5),\n",
    "                                A.RandomRotate90(p=0.5)])\n",
    "else:\n",
    "    transform_set = None\n",
    "\n",
    "dm = OCS_DataModule(\n",
    "    dict_train=dict_train,\n",
    "    dict_val=dict_val,\n",
    "    dict_test=dict_test,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    "    num_classes=13,\n",
    "    num_channels=5,\n",
    "    use_metadata=use_metadata,\n",
    "    use_augmentations=transform_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2069ada-8d0a-49e6-82af-6dfb477cdfe7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "f2069ada-8d0a-49e6-82af-6dfb477cdfe7",
    "tags": []
   },
   "source": [
    "### Model\n",
    "<font color='#90c149'>Note:</font> the next cell will trigger the download of ResNet34 (default for U-Net architecture in pytorch-lightning) with pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdc448b-40fa-4e3f-bfe4-7c506ba60820",
   "metadata": {
    "id": "0cdc448b-40fa-4e3f-bfe4-7c506ba60820"
   },
   "outputs": [],
   "source": [
    "model = SMP_Unet_meta(n_channels=5, n_classes=13, use_metadata=use_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8c2f2-8241-448e-a534-accbae1b6bf2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "a7f8c2f2-8241-448e-a534-accbae1b6bf2",
    "tags": []
   },
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fedcbc1-9da5-4167-9407-9c4dc427cdbb",
   "metadata": {
    "id": "4fedcbc1-9da5-4167-9407-9c4dc427cdbb"
   },
   "outputs": [],
   "source": [
    "if use_weights == True:\n",
    "    with torch.no_grad():\n",
    "        class_weights = torch.FloatTensor(class_weights)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c65e30a-91ce-463b-9168-8b09c827f7a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2c65e30a-91ce-463b-9168-8b09c827f7a6",
    "tags": []
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86049ef-0f11-4654-85d9-2797a86e33c7",
   "metadata": {
    "id": "c86049ef-0f11-4654-85d9-2797a86e33c7"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbcef33-579c-4b33-b43b-dcfdfb5689a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0bbcef33-579c-4b33-b43b-dcfdfb5689a5",
    "tags": []
   },
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66a33fb-44f0-462c-8735-ddefa6d09ee3",
   "metadata": {
    "id": "d66a33fb-44f0-462c-8735-ddefa6d09ee3"
   },
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    cooldown=4,\n",
    "    min_lr=1e-7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee60d0-823d-46fd-957c-e9341fa3aa25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "70ee60d0-823d-46fd-957c-e9341fa3aa25",
    "tags": []
   },
   "source": [
    "### Pytorch lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d2f5dc2-4163-490a-8e41-f8742ba5efc9",
   "metadata": {
    "id": "4d2f5dc2-4163-490a-8e41-f8742ba5efc9"
   },
   "outputs": [],
   "source": [
    "seg_module = SegmentationTask(\n",
    "    model=model,\n",
    "    num_classes=dm.num_classes,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    use_metadata=use_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9d2cbb-f1ac-4f8d-88f5-f347c0a9e6e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0b9d2cbb-f1ac-4f8d-88f5-f347c0a9e6e8",
    "tags": []
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2041fd30-c39e-49ee-9cb7-f00774ffb1b2",
   "metadata": {
    "id": "2041fd30-c39e-49ee-9cb7-f00774ffb1b2"
   },
   "outputs": [],
   "source": [
    "ckpt_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=os.path.join(out_dir,\"checkpoints\"),\n",
    "    filename=\"ckpt-{epoch:02d}-{val_loss:.2f}\"+'_'+out_model_name,\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    "    save_weights_only=True, # can be changed accordingly\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00,\n",
    "    patience=30, # if no improvement after 30 epoch, stop learning. \n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "prog_rate = TQDMProgressBar(refresh_rate=progress_rate)\n",
    "\n",
    "callbacks = [\n",
    "    ckpt_callback, \n",
    "    early_stop_callback,\n",
    "    prog_rate,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d51b5-249d-4838-bbb6-dca8ba997ff9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d63d51b5-249d-4838-bbb6-dca8ba997ff9",
    "tags": []
   },
   "source": [
    "### Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56fda75-3b52-4a4e-874f-083c06b446e6",
   "metadata": {
    "id": "c56fda75-3b52-4a4e-874f-083c06b446e6"
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    save_dir=out_dir,\n",
    "    name=Path(\"tensorboard_logs\"+'_'+out_model_name).as_posix()\n",
    ")\n",
    "\n",
    "loggers = [\n",
    "    logger\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7248b8bc-638e-4085-bd83-7baa94cd094b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7248b8bc-638e-4085-bd83-7baa94cd094b",
    "tags": []
   },
   "source": [
    "## <font color='#90c149'>Launch the training</font>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "Defining a `Trainer` allows for to automate tasks, such as enabling/disabling grads, running the dataloaders or invoking the callbacks when needed.\n",
    "<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ceb0de-9a75-43e9-be60-a7a4a1640d7b",
   "metadata": {
    "id": "19ceb0de-9a75-43e9-be60-a7a4a1640d7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#### instanciation of  Trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=accelerator,\n",
    "    devices=gpus_per_node,\n",
    "    strategy=strategy,\n",
    "    num_nodes=num_nodes,\n",
    "    max_epochs=num_epochs,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks = callbacks,\n",
    "    logger=loggers,\n",
    "    enable_progress_bar = enable_progress_bar,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cFE9DTm3A8df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cFE9DTm3A8df",
    "tags": []
   },
   "source": [
    "<br/><hr>\n",
    "\n",
    "<font color='#90c149'>Let's launch the training.</font>\n",
    "<br/><hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5afd841a-9468-4d68-b2a8-aa5dac2d6f60",
   "metadata": {
    "id": "5afd841a-9468-4d68-b2a8-aa5dac2d6f60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type                   | Params\n",
      "---------------------------------------------------------\n",
      "0 | model         | SMP_Unet_meta          | 24.4 M\n",
      "1 | criterion     | CrossEntropyLoss       | 0     \n",
      "2 | train_metrics | MulticlassJaccardIndex | 0     \n",
      "3 | val_metrics   | MulticlassJaccardIndex | 0     \n",
      "4 | train_loss    | MeanMetric             | 0     \n",
      "5 | val_loss      | MeanMetric             | 0     \n",
      "---------------------------------------------------------\n",
      "24.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.4 M    Total params\n",
      "97.778    Total estimated model params size (MB)\n",
      "/opt/conda/envs/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/envs/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   8%|â–Š         | 650/7713 [05:43<1:02:13,  1.89it/s, loss=1.31, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(seg_module, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48978bf6-4d34-4308-ad8a-105efb45ea79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "48978bf6-4d34-4308-ad8a-105efb45ea79",
    "tags": []
   },
   "source": [
    "## <font color='#90c149'>Check metrics on the validation dataset</font>\n",
    "\n",
    "<br/><hr> \n",
    "\n",
    "To give an idea on the training results, we call validate on the trainer to print some metrics. <hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d96d9d7-da3c-4266-9f4b-712f4c923aa6",
   "metadata": {
    "id": "8d96d9d7-da3c-4266-9f4b-712f4c923aa6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mvalidate(seg_module, datamodule\u001b[38;5;241m=\u001b[39mdm)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.validate(seg_module, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3984d2d-7ed0-4d9b-8d47-47fce2d88987",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "a3984d2d-7ed0-4d9b-8d47-47fce2d88987",
    "tags": []
   },
   "source": [
    "## <font color='#90c149'>Inference and predictions export</font>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "For inference, we define a new callback, `PredictionWriter`, which is used to export the predictions on the test dataset.<br/><br/>\n",
    "<font color='#90c149'>Note:</font> the callback exports the files with the mandotary formatting of outputs (files named <font color='red'><b> PRED_{ID].tif</b></font>, with datatype <font color='red'><b>uint8</b></font> and <font color='red'><b>LZW</b></font> compression), using Pillow.\n",
    "Check the <font color='#D7881C'><em>writer.py</em></font> file for details.<br/><br/>\n",
    "\n",
    "We instantiate a new `Trainer` with this newly defined callback and call predict.\n",
    "<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "329190c2-040d-4a77-a27d-3239286e01e4",
   "metadata": {
    "id": "329190c2-040d-4a77-a27d-3239286e01e4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m writer_callback \u001b[38;5;241m=\u001b[39m PredictionWriter(        \n\u001b[1;32m----> 2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mout_dir\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mout_model_name),\n\u001b[0;32m      3\u001b[0m     write_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#### instanciation of prediction Trainer\u001b[39;00m\n\u001b[0;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      8\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39maccelerator,\n\u001b[0;32m      9\u001b[0m     devices\u001b[38;5;241m=\u001b[39mgpus_per_node,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     enable_progress_bar \u001b[38;5;241m=\u001b[39m enable_progress_bar,\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out_dir' is not defined"
     ]
    }
   ],
   "source": [
    "writer_callback = PredictionWriter(        \n",
    "    output_dir=os.path.join(out_dir, \"predictions\"+\"_\"+out_model_name),\n",
    "    write_interval=\"batch\",\n",
    ")\n",
    "\n",
    "#### instanciation of prediction Trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=accelerator,\n",
    "    devices=gpus_per_node,\n",
    "    strategy=strategy,\n",
    "    num_nodes=num_nodes,\n",
    "    callbacks = [writer_callback],\n",
    "    enable_progress_bar = enable_progress_bar,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e36febba-49d1-410f-a60f-1fba724e9f76",
   "metadata": {
    "id": "e36febba-49d1-410f-a60f-1fba724e9f76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: C:\\Users\\marka\\Documents\\New folder\\lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dbcf1eb2c5418ba4b8362920fcb64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--  [FINISHED.]  --\n",
      "output dir : \\content\\gdrive\\MyDrive\\models_output\\flair-one-baseline_argu\n"
     ]
    }
   ],
   "source": [
    "trainer.predict(seg_module, datamodule=dm)\n",
    "\n",
    "@rank_zero_only\n",
    "def print_finish():\n",
    "    print('--  [FINISHED.]  --', f'output dir : {out_dir}', sep='\\n')\n",
    "print_finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b7e1da-f928-4b73-8014-a5ed49fd38ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "09b7e1da-f928-4b73-8014-a5ed49fd38ea",
    "tags": []
   },
   "source": [
    "## <font color='#90c149'>Visual checking of predictions</font>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "<font color='#90c149'>For the test set, obviously, you do not have access to the masks.</font> Nevertheless, we can visually display some predictions alongside the RGB images.<br/><br/>\n",
    "\n",
    "First, we create lists containing the paths to the test RGB images (`images_test`) as well as the predicted semantic segmentation masks (`predictions`).<br/><br/>\n",
    "\n",
    "\n",
    "\n",
    "We then display some random couples of predictions together with their corresponding aerial RGB images.<br/><br/>\n",
    "\n",
    "<font color='#90c149'><em>Note 1</em></font>: if you are using the toy dataset, don't expect accurate predictions. A set of $200$ training samples will give limited results.<br/> \n",
    "<font color='#90c149'><em>Note 2</em></font>: rasterio will yield a <em>NotGeoreferencedWarning</em> regarding the predictions files. This is normal as the prediction files have been written without any geographical information, which is expected by rasterio. This kind of information is not important for assessing the model outputs, so we can just omit the warning.\n",
    "<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1e31b62-590a-4a61-9b95-4be828159cff",
   "metadata": {
    "id": "a1e31b62-590a-4a61-9b95-4be828159cff"
   },
   "outputs": [],
   "source": [
    "from py_module.data_display import display_predictions, get_data_paths\n",
    "\n",
    "images_test = sorted(list(get_data_paths(Path(path_data,'test'), 'IMG*.tif')), key=lambda x: int(x.split('_')[-1][:-4]))\n",
    "predictions = sorted(list(get_data_paths(Path(out_dir, \"predictions\"+'_'+out_model_name), 'PRED*.tif')), key=lambda x: int(x.split('_')[-1][:-4]))\n",
    "display_predictions(images_test, predictions, nb_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb236d-2c92-4140-88af-6a67d74e9b05",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "84bb236d-2c92-4140-88af-6a67d74e9b05",
    "tags": []
   },
   "source": [
    "## <font color='#90c149'>Metric calculation: mIoU</font>\n",
    "\n",
    "<br/><hr>\n",
    "\n",
    "As mentioned before, the masks of the test set are not available. However, the following cell describes the code that is used to calculate the metric used over the test set and to consequently rank the best models. Again, the toy dataset contains $50$ test pastches, while the full FLAIR-one dataset contains $15,700$ test patches.<br/><br/>\n",
    "\n",
    "The calculation of the mean Intersection-over-Union (`mIou`) is based on the confusion matrix $C$, which is determined for each test patch. The confusion matrices are subsequently summed providing the confusion matrix describing the test set. Per-class IoU, defined as the ratio between true positives divided by the sum of false positives, false negatives and true positives is calculated from the summed confusion matrix as follows: <br/><br/>\n",
    "    $$\n",
    "    IoU_i = \\frac{C_{i,i}}\n",
    "    {C_{i,i} + \\sum_{j \\neq i}\\left(C_{i,j} + C_{j,i} \\right)} = \\frac{TP}{TP+FP+FN}\n",
    "    $$\n",
    "<br>\n",
    "The final `mIou` is then the average of the per-class IoUs. \n",
    "\n",
    "\n",
    "<font color='#90c149'><em>Note:</em></font> as the <font color='#90c149'><em>'other'</em></font> class is <font color='#90c149'>not well defined (void)</font>, its IoU is <font color='#90c149'>removed</font> and therefore does not contribute to the calculation of the `mIou`. In other words,  the remaining per-class IoUs (all except 'other') are averaged by 12 and not 13 to obtain the final `mIou`.</font>\n",
    "\n",
    "<hr><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cde8904-2b0d-4273-9619-42108e3a80c7",
   "metadata": {
    "id": "9cde8904-2b0d-4273-9619-42108e3a80c7"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def generate_miou(path_truth: str, path_pred: str) -> list:\n",
    "  \n",
    "    #################################################################################################\n",
    "    def get_data_paths (path, filter):\n",
    "        for path in Path(path).rglob(filter):\n",
    "             yield path.resolve().as_posix()  \n",
    "                \n",
    "    def calc_miou(cm_array):\n",
    "        m = np.nan\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            ious = np.diag(cm_array) / (cm_array.sum(0) + cm_array.sum(1) - np.diag(cm_array))\n",
    "        m = np.nansum(ious[:-1]) / (np.logical_not(np.isnan(ious[:-1]))).sum()\n",
    "        return m.astype(float), ious[:-1]      \n",
    "\n",
    "    #################################################################################################\n",
    "                       \n",
    "    truth_images = sorted(list(get_data_paths(Path(path_truth), 'MSK*.tif')), key=lambda x: int(x.split('_')[-1][:-4]))\n",
    "    preds_images  = sorted(list(get_data_paths(Path(path_pred), 'PRED*.tif')), key=lambda x: int(x.split('_')[-1][:-4]))\n",
    "    if len(truth_images) != len(preds_images): \n",
    "        print('[WARNING !] mismatch number of predictions and test files.')\n",
    "    if truth_images[0][-10:-4] != preds_images[0][-10:-4] or truth_images[-1][-10:-4] != preds_images[-1][-10:-4]: \n",
    "        print('[WARNING !] unsorted images and masks found ! Please check filenames.') \n",
    "        \n",
    "    patch_confusion_matrices = []\n",
    "\n",
    "    for u in range(len(truth_images)):\n",
    "        target = np.array(Image.open(truth_images[u]))-1 # -1 as model predictions start at 0 and turth at 1.\n",
    "        target[target>12]=12  ### remapping masks to reduced baseline nomenclature.\n",
    "        preds = np.array(Image.open(preds_images[u]))         \n",
    "        patch_confusion_matrices.append(confusion_matrix(target.flatten(), preds.flatten(), labels=list(range(13))))\n",
    "\n",
    "    sum_confmat = np.sum(patch_confusion_matrices, axis=0)\n",
    "    mIou, ious = calc_miou(sum_confmat) \n",
    "\n",
    "    return mIou, ious\n",
    "\n",
    "\n",
    "#if name == \"__main__\":  \n",
    "#    truth_msk = './reference/\n",
    "#    pred_msk  = './predictions/'\n",
    "#    mIou = generate_miou(truth_images, truth_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6134d3c7-7e18-4a73-a88f-7e3eeb89c6e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'truth_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m truth_msk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./reference/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m pred_msk  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./predictions/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m mIou \u001b[38;5;241m=\u001b[39m generate_miou(\u001b[43mtruth_images\u001b[49m, truth_msk)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'truth_images' is not defined"
     ]
    }
   ],
   "source": [
    "truth_msk = './reference/'\n",
    "pred_msk  = './predictions/'\n",
    "mIou = generate_miou(truth_images, truth_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf132db-3446-4d68-bb1c-cb227c559882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
